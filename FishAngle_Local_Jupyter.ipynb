{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccae5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import shutil, os, glob, random, json\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bf9f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['0', '135', '180', '225', '270', '315', '45', '90']\n",
      "Imágenes -> train:760  val:159  test:171\n"
     ]
    }
   ],
   "source": [
    "# Ajusta estas rutas a tus carpetas locales:\n",
    "SOURCE_DIR = r\"D:\\Proyectos\\Salmones\\fish_angles_raw\"   \n",
    "DATASET_DIR = r\"D:\\Proyectos\\Salmones\\fish_angle_cls\"   # se creará con train/val/test\n",
    "\n",
    "splits = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}\n",
    "\n",
    "# Limpia si ya existía\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    shutil.rmtree(DATASET_DIR)\n",
    "for sp in [\"train\",\"val\",\"test\"]:\n",
    "    os.makedirs(os.path.join(DATASET_DIR, sp), exist_ok=True)\n",
    "\n",
    "# Detecta clases\n",
    "classes = sorted([d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))])\n",
    "print(\"Clases detectadas:\", classes)\n",
    "\n",
    "# Crea subcarpetas por split y clase\n",
    "for sp in [\"train\",\"val\",\"test\"]:\n",
    "    for c in classes:\n",
    "        os.makedirs(os.path.join(DATASET_DIR, sp, c), exist_ok=True)\n",
    "\n",
    "# Split estratificado simple por carpeta\n",
    "for c in classes:\n",
    "    imgs = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "        imgs.extend(glob.glob(os.path.join(SOURCE_DIR, c, ext)))\n",
    "    random.shuffle(imgs)\n",
    "    n = len(imgs)\n",
    "    n_train = int(n * splits[\"train\"])\n",
    "    n_val   = int(n * splits[\"val\"])\n",
    "    train_files = imgs[:n_train]\n",
    "    val_files   = imgs[n_train:n_train+n_val]\n",
    "    test_files  = imgs[n_train+n_val:]\n",
    "\n",
    "    def copy(files, split):\n",
    "        for f in files:\n",
    "            shutil.copy2(f, os.path.join(DATASET_DIR, split, c))\n",
    "    copy(train_files, \"train\")\n",
    "    copy(val_files,   \"val\")\n",
    "    copy(test_files,  \"test\")\n",
    "\n",
    "sum_train = sum(len(glob.glob(os.path.join(DATASET_DIR,\"train\",c,\"*\"))) for c in classes)\n",
    "sum_val   = sum(len(glob.glob(os.path.join(DATASET_DIR,\"val\",c,\"*\"))) for c in classes)\n",
    "sum_test  = sum(len(glob.glob(os.path.join(DATASET_DIR,\"test\",c,\"*\"))) for c in classes)\n",
    "print(f\"Imágenes -> train:{sum_train}  val:{sum_val}  test:{sum_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f5009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['0', '135', '180', '225', '270', '315', '45', '90']\n",
      "Total en R (train+val): 919\n",
      "Total en TEST externo : 171\n"
     ]
    }
   ],
   "source": [
    "# Construir R (train+val) para Cross-Validation, dejando test como externo ===\n",
    "import os, shutil, glob\n",
    "\n",
    "R_DIR = os.path.join(os.path.dirname(DATASET_DIR), \"fish_angle_R\")\n",
    "if os.path.exists(R_DIR):\n",
    "    shutil.rmtree(R_DIR)\n",
    "os.makedirs(R_DIR, exist_ok=True)\n",
    "\n",
    "classes = sorted([d for d in os.listdir(os.path.join(DATASET_DIR, \"train\"))\n",
    "                  if os.path.isdir(os.path.join(DATASET_DIR, \"train\", d))])\n",
    "\n",
    "for c in classes:\n",
    "    os.makedirs(os.path.join(R_DIR, c), exist_ok=True)\n",
    "\n",
    "# Si ejecutaste la Celda 3, puedes excluir derivados con sufijos (descomenta para filtrar):\n",
    "DERIV_SUFFIXES = [\"_rot180\", \"_rot180_\"]\n",
    "def es_derivada(path):\n",
    "    base = os.path.basename(path)\n",
    "    return any(suf in base for suf in DERIV_SUFFIXES)\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    for c in classes:\n",
    "        src = os.path.join(DATASET_DIR, split, c)\n",
    "        dst = os.path.join(R_DIR, c)\n",
    "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "            for p in glob.glob(os.path.join(src, ext)):\n",
    "                if es_derivada(p):\n",
    "                    continue\n",
    "                shutil.copy2(p, dst)\n",
    "\n",
    "def count_in(base):\n",
    "    return sum(len(glob.glob(os.path.join(base, c, \"*\"))) for c in classes)\n",
    "\n",
    "print(\"Clases:\", classes)\n",
    "print(\"Total en R (train+val):\", count_in(R_DIR))\n",
    "print(\"Total en TEST externo :\", sum(len(glob.glob(os.path.join(DATASET_DIR, 'test', c, '*'))) for c in classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639c54a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === K-Fold CV limpio + aumentos controlados ===\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      6\u001b[39m CLASSES   = [\u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m45\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m90\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m135\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m180\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m225\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m270\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m315\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# === K-Fold CV limpio + aumentos controlados ===\n",
    "import os, glob, shutil, random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "\n",
    "CLASSES   = ['0','45','90','135','180','225','270','315']\n",
    "FOLDS_DIR = os.path.join(os.path.dirname(DATASET_DIR), \"fish_angle_folds\")\n",
    "K = 5\n",
    "\n",
    "# tope de refuerzo para 90° desde 270° (ej. 0.5 = +50%, 1.0 = +100%)\n",
    "CAP_RATIO_90 = 1.0\n",
    "\n",
    "def list_imgs(d):\n",
    "    files = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "        files += glob.glob(os.path.join(d, ext))\n",
    "    return sorted(files)\n",
    "\n",
    "def list_imgs_orig(d):\n",
    "    # Solo originales: evita usar derivados (que contengan \"_rot\")\n",
    "    return [p for p in list_imgs(d) if \"_rot\" not in os.path.basename(p).lower()]\n",
    "\n",
    "def safe_copy(paths, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for p in paths:\n",
    "        shutil.copy2(p, out_dir)\n",
    "\n",
    "def save_unique(im, dst_dir, base, suffix, ext):\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    out = os.path.join(dst_dir, f\"{base}_{suffix}{ext}\")\n",
    "    i = 1\n",
    "    while os.path.exists(out):\n",
    "        out = os.path.join(dst_dir, f\"{base}_{suffix}_{i}{ext}\")\n",
    "        i += 1\n",
    "    im.save(out)\n",
    "\n",
    "def list_samples_and_labels(base_dir, classes):\n",
    "    samples, labels = [], []\n",
    "    for c in classes:\n",
    "        cdir = os.path.join(base_dir, c)\n",
    "        for p in list_imgs_orig(cdir):   # <-- SOLO originales\n",
    "            samples.append(p); labels.append(c)\n",
    "    return samples, labels\n",
    "\n",
    "# --- Construye lista de muestras (solo originales) desde R_DIR ---\n",
    "samples, labels = list_samples_and_labels(R_DIR, CLASSES)\n",
    "\n",
    "# --- LIMPIA folds previos ---\n",
    "if os.path.exists(FOLDS_DIR):\n",
    "    shutil.rmtree(FOLDS_DIR)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "fold_specs = []\n",
    "\n",
    "for k, (train_idx, val_idx) in enumerate(skf.split(samples, labels)):\n",
    "    fold_root = os.path.join(FOLDS_DIR, f\"fold_{k}\")\n",
    "    tr_dir = os.path.join(fold_root, \"train\")\n",
    "    va_dir = os.path.join(fold_root, \"val\")\n",
    "\n",
    "    # Estructura de carpetas\n",
    "    for d in [tr_dir, va_dir]:\n",
    "        for c in CLASSES:\n",
    "            os.makedirs(os.path.join(d, c), exist_ok=True)\n",
    "\n",
    "    # Copia SOLO originales a train/ y val/\n",
    "    train_paths = [samples[i] for i in train_idx]\n",
    "    val_paths   = [samples[i] for i in val_idx]\n",
    "    for p in train_paths:\n",
    "        c = os.path.basename(os.path.dirname(p))\n",
    "        safe_copy([p], os.path.join(tr_dir, c))\n",
    "    for p in val_paths:\n",
    "        c = os.path.basename(os.path.dirname(p))\n",
    "        safe_copy([p], os.path.join(va_dir, c))\n",
    "\n",
    "    # Conteos crudos (sin aumentos)\n",
    "    n90_raw  = len(list_imgs(os.path.join(tr_dir, \"90\")))\n",
    "    n270_raw = len(list_imgs(os.path.join(tr_dir, \"270\")))\n",
    "    print(f\"[fold {k}] RAW train -> 90:{n90_raw}  270:{n270_raw}\")\n",
    "\n",
    "    # Aumentos base: 0 <-> 180 (rotar 180° ambos sentidos) SOLO en train\n",
    "    # Importante: usar SIEMPRE DONANTES ORIGINALES para evitar cadenas\n",
    "    for rec, don in [(\"0\",\"180\"), (\"180\",\"0\")]:\n",
    "        src = os.path.join(tr_dir, don)\n",
    "        dst = os.path.join(tr_dir, rec)\n",
    "        donors = list_imgs_orig(src)\n",
    "        for f in donors:\n",
    "            base, ext = os.path.splitext(os.path.basename(f))\n",
    "            with Image.open(f) as im:\n",
    "                im2 = im.rotate(180, expand=False)\n",
    "                save_unique(im2, dst, base, f\"from{don}_rot180\", ext)\n",
    "\n",
    "    dst90  = os.path.join(tr_dir, \"90\")\n",
    "    src180 = os.path.join(tr_dir, \"180\")\n",
    "    cap_add = max(1, int(CAP_RATIO_90 * n90_raw))\n",
    "    donors180 = list_imgs_orig(src180)\n",
    "    random.shuffle(donors180)\n",
    "    to_add = min(cap_add, len(donors180))\n",
    "    print(f\"[fold {k}] 90° crudo={n90_raw}, add from 180: {to_add} (cap={CAP_RATIO_90:.2f}x)\")\n",
    "\n",
    "    for f in donors180[:to_add]:\n",
    "        base, ext = os.path.splitext(os.path.basename(f))\n",
    "        with Image.open(f) as im:\n",
    "            im2 = im.rotate(270, expand=True)\n",
    "            save_unique(im2, dst90, base, \"from180_rot270\", ext)\n",
    "\n",
    "    n90_final = len(list_imgs(dst90))\n",
    "    print(f\"[fold {k}] RESULT train -> 90:{n90_final}\")\n",
    "\n",
    "    fold_specs.append({\"root\": fold_root, \"train\": tr_dir, \"val\": va_dir})\n",
    "    print(f\"Fold {k} listo → {fold_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c2e05",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Entrenar cada fold y promediar métricas ===\n",
    "from ultralytics import YOLO\n",
    "import json, os\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for k, spec in enumerate(fold_specs):\n",
    "    print(f\"\\n=== Entrenando fold {k}/{len(fold_specs)-1} ===\")\n",
    "    model = YOLO(\"yolo11m-cls.pt\")\n",
    "    res = model.train(\n",
    "        data=spec[\"root\"],\n",
    "        epochs=50,\n",
    "        imgsz=256,\n",
    "        batch=32,\n",
    "        lr0=0.001,          # ok\n",
    "        cos_lr=True,\n",
    "        lrf=0.05,           # <-- sube de 0.01 a 0.05\n",
    "        optimizer=\"AdamW\",\n",
    "        patience=15,\n",
    "        auto_augment=None,\n",
    "        erasing=0.0,\n",
    "        workers=0,\n",
    "        fliplr=0.0, translate=0.0, scale=0.0, mosaic=0.0,\n",
    "        hsv_h=0.0, hsv_s=0.05, hsv_v=0.05,   # <-- ligero y seguro\n",
    "        project=\"runs_cls_cv\",\n",
    "        name=f\"fish_angle_y11n_fold{k}\"\n",
    "    )\n",
    "\n",
    "    # (A) Matriz de confusión del VAL del fold k\n",
    "    valres = model.val(\n",
    "        data=spec[\"root\"],   # este root tiene train/ y val/ del fold\n",
    "        split=\"val\",\n",
    "        imgsz=256,\n",
    "        batch=32,\n",
    "        workers=0,\n",
    "        plots=True           # <- esto guarda la imagen en la carpeta del experimento del fold\n",
    "    )\n",
    "\n",
    "\n",
    "    mdict = {}\n",
    "    try:\n",
    "        mdict = res.results_dict\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    exp_dir = getattr(res, \"save_dir\", None)\n",
    "    if exp_dir:\n",
    "        mj = os.path.join(exp_dir, \"results.json\")\n",
    "        if os.path.exists(mj):\n",
    "            try:\n",
    "                with open(mj, \"r\") as f:\n",
    "                    j = json.load(f)\n",
    "                if isinstance(j, dict):\n",
    "                    mdict.update(j)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    all_metrics.append(mdict)\n",
    "\n",
    "def mean_key(key):\n",
    "    vals = [m[key] for m in all_metrics if key in m]\n",
    "    return sum(vals)/len(vals) if vals else None\n",
    "\n",
    "print(\"\\n=== PROMEDIO CV ===\")\n",
    "print(\"Top-1 acc (mean):\", mean_key(\"metrics/accuracy_top1\"))\n",
    "print(\"Top-5 acc (mean):\", mean_key(\"metrics/accuracy_top5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef3d52-cf3b-4df8-962c-da3e455ba3d0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Entrenamiento final en R (como train y val) y evaluación en test externo ===\n",
    "import os, glob, shutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "R_DIR = r\"D:\\Proyectos\\Salmones\\fish_angle_R\"\n",
    "FINAL_ROOT = r\"D:\\Proyectos\\Salmones\\fish_angle_FINAL\"\n",
    "if os.path.isdir(FINAL_ROOT):\n",
    "    shutil.rmtree(FINAL_ROOT)\n",
    "for sp in [\"train\", \"val\"]:\n",
    "    os.makedirs(os.path.join(FINAL_ROOT, sp), exist_ok=True)\n",
    "\n",
    "classes = sorted([d for d in os.listdir(R_DIR) if os.path.isdir(os.path.join(R_DIR, d))])\n",
    "for sp in [\"train\", \"val\"]:\n",
    "    for c in classes:\n",
    "        os.makedirs(os.path.join(FINAL_ROOT, sp, c), exist_ok=True)\n",
    "\n",
    "def place_file(src, dst):\n",
    "    try: os.link(src, dst)\n",
    "    except: shutil.copy2(src, dst)\n",
    "\n",
    "for c in classes:\n",
    "    src_c = os.path.join(R_DIR, c)\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "        for p in glob.glob(os.path.join(src_c, ext)):\n",
    "            base = os.path.basename(p)\n",
    "            place_file(p, os.path.join(FINAL_ROOT, \"train\", c, base))\n",
    "            place_file(p, os.path.join(FINAL_ROOT, \"val\",   c, base))\n",
    "\n",
    "print(\"FINAL_ROOT listo:\", FINAL_ROOT)\n",
    "\n",
    "model = YOLO(\"yolo11m-cls.pt\")\n",
    "res = model.train(\n",
    "    data=FINAL_ROOT,\n",
    "    epochs=50,\n",
    "    imgsz=256,\n",
    "    batch=32,\n",
    "    lr0=0.001,\n",
    "    cos_lr=True,\n",
    "    lrf=0.05,           # <-- igual que arriba\n",
    "    optimizer=\"AdamW\",\n",
    "    patience=15,\n",
    "    auto_augment=None,\n",
    "    erasing=0.0,\n",
    "    workers=0,\n",
    "    fliplr=0.0, translate=0.0, scale=0.0, mosaic=0.0,\n",
    "    hsv_h=0.0, hsv_s=0.05, hsv_v=0.05,\n",
    "    project=\"runs_cls_final\",\n",
    "    name=\"fish_angle_y11n_final_R256\"\n",
    ")\n",
    "\n",
    "\n",
    "DATASET_DIR = r\"D:\\Proyectos\\Salmones\\fish_angle_cls\"\n",
    "final_metrics = model.val(\n",
    "    data=DATASET_DIR,\n",
    "    split=\"test\",\n",
    "    imgsz=256,\n",
    "    batch=32,\n",
    "    workers=0,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== MÉTRICAS EN TEST EXTERNO ===\")\n",
    "try:\n",
    "    print(final_metrics.results_dict)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b7bbc-f194-442f-9f9b-960785a19bc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os, glob, numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "BEST = r\"D:\\Proyectos\\Salmones\\runs_cls_final\\fish_angle_y11n_final_R2569\\weights/best.pt\"  # o pon la ruta exacta\n",
    "DATASET_DIR = r\"D:\\Proyectos\\Salmones\\fish_angle_cls\"\n",
    "\n",
    "model = YOLO(BEST)\n",
    "classes = sorted([d for d in os.listdir(os.path.join(DATASET_DIR,\"test\")) if os.path.isdir(os.path.join(DATASET_DIR,\"test\",d))])\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "name_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "\n",
    "for c in classes:\n",
    "    cdir = os.path.join(DATASET_DIR, \"test\", c)\n",
    "    files = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\"):\n",
    "        files += glob.glob(os.path.join(cdir, ext))\n",
    "    for f in files:\n",
    "        r = model.predict(f, imgsz=256, verbose=False)\n",
    "        top1 = int(np.argmax(r[0].probs.data.cpu().numpy()))\n",
    "        y_true.append(name_to_idx[c]); y_pred.append(top1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
